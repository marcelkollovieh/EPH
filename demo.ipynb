{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "import yaml\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import pytorch_lightning as pl\n",
    "\n",
    "from eph_clustering.models import EPH\n",
    "from eph_clustering.data import EPHDataModule, ProbabilisticEPHDataModule\n",
    "from eph_clustering.util import (\n",
    "    get_initial_hierarchy,\n",
    "    best_tree,\n",
    "    Losses,\n",
    "    compute_skn_tsd,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 6432\n"
     ]
    }
   ],
   "source": [
    "def parse_config(config_path):\n",
    "    with open(config_path, \"r\") as fp:\n",
    "        config = yaml.safe_load(fp)\n",
    "    pl.seed_everything(config[\"seed\"])\n",
    "    gumbel_samples = config[\"model_params\"].pop(\"gumbel_samples\")\n",
    "    config[\"dataset_params\"][\"gumbel_samples\"] = gumbel_samples\n",
    "    config[\"training_params\"][\"gumbel_samples\"] = gumbel_samples\n",
    "    return config\n",
    "\n",
    "\n",
    "config = parse_config(\"./configs/exp_das_citeseer.yaml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'datasets/citeseer.pkl.gzip'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mFileNotFoundError\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[11], line 12\u001B[0m\n\u001B[1;32m      6\u001B[0m     data_module \u001B[38;5;241m=\u001B[39m ProbabilisticEPHDataModule\u001B[38;5;241m.\u001B[39mfrom_pickle(\n\u001B[1;32m      7\u001B[0m         \u001B[38;5;28mstr\u001B[39m(file_path),\n\u001B[1;32m      8\u001B[0m         dtype\u001B[38;5;241m=\u001B[39mtorch\u001B[38;5;241m.\u001B[39mfloat32,\n\u001B[1;32m      9\u001B[0m         \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mconfig[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mdataset_params\u001B[39m\u001B[38;5;124m\"\u001B[39m],\n\u001B[1;32m     10\u001B[0m     )\n\u001B[1;32m     11\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m---> 12\u001B[0m     data_module \u001B[38;5;241m=\u001B[39m \u001B[43mEPHDataModule\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfrom_pickle\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m     13\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43mstr\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mfile_path\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     14\u001B[0m \u001B[43m        \u001B[49m\u001B[43mdtype\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfloat32\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     15\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mconfig\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mdataset_params\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     16\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Documents/MasterThesis/EPH/src/eph_clustering/data/data_modules.py:184\u001B[0m, in \u001B[0;36mEPHDataModule.from_pickle\u001B[0;34m(self, path, make_undirected, make_unweighted, remove_selfloops, select_lcc, dtype, gumbel_samples, normalize_graph, **kwargs)\u001B[0m\n\u001B[1;32m    171\u001B[0m \u001B[38;5;129m@classmethod\u001B[39m\n\u001B[1;32m    172\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mfrom_pickle\u001B[39m(\n\u001B[1;32m    173\u001B[0m     \u001B[38;5;28mself\u001B[39m,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    182\u001B[0m     \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs,\n\u001B[1;32m    183\u001B[0m ):\n\u001B[0;32m--> 184\u001B[0m     dataset \u001B[38;5;241m=\u001B[39m \u001B[43mEPHDataset\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfrom_pickle\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    185\u001B[0m \u001B[43m        \u001B[49m\u001B[43mpath\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    186\u001B[0m \u001B[43m        \u001B[49m\u001B[43mmake_undirected\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmake_undirected\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    187\u001B[0m \u001B[43m        \u001B[49m\u001B[43mmake_unweighted\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmake_unweighted\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    188\u001B[0m \u001B[43m        \u001B[49m\u001B[43mremove_selfloops\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mremove_selfloops\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    189\u001B[0m \u001B[43m        \u001B[49m\u001B[43mselect_lcc\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mselect_lcc\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    190\u001B[0m \u001B[43m        \u001B[49m\u001B[43mdtype\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdtype\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    191\u001B[0m \u001B[43m        \u001B[49m\u001B[43mbatches_per_epoch\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mgumbel_samples\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    192\u001B[0m \u001B[43m        \u001B[49m\u001B[43mnormalize_graph\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mnormalize_graph\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    193\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    195\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m gumbel_samples \u001B[38;5;241m!=\u001B[39m \u001B[38;5;241m1\u001B[39m:\n\u001B[1;32m    196\u001B[0m         val_dataset \u001B[38;5;241m=\u001B[39m EPHDataset\u001B[38;5;241m.\u001B[39mfrom_pickle(\n\u001B[1;32m    197\u001B[0m             path,\n\u001B[1;32m    198\u001B[0m             make_undirected\u001B[38;5;241m=\u001B[39mmake_undirected,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    203\u001B[0m             dtype\u001B[38;5;241m=\u001B[39mdtype,\n\u001B[1;32m    204\u001B[0m         )\n",
      "File \u001B[0;32m~/Documents/MasterThesis/EPH/src/eph_clustering/data/data_modules.py:95\u001B[0m, in \u001B[0;36mEPHDataset.from_pickle\u001B[0;34m(self, path, make_undirected, make_unweighted, remove_selfloops, select_lcc, dtype, batches_per_epoch, normalize_graph)\u001B[0m\n\u001B[1;32m     82\u001B[0m \u001B[38;5;129m@classmethod\u001B[39m\n\u001B[1;32m     83\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mfrom_pickle\u001B[39m(\n\u001B[1;32m     84\u001B[0m     \u001B[38;5;28mself\u001B[39m,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m     92\u001B[0m     normalize_graph\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m,\n\u001B[1;32m     93\u001B[0m ):\n\u001B[1;32m     94\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m path\u001B[38;5;241m.\u001B[39mendswith(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m.gzip\u001B[39m\u001B[38;5;124m\"\u001B[39m):\n\u001B[0;32m---> 95\u001B[0m         \u001B[38;5;28;01mwith\u001B[39;00m \u001B[43mgzip\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mopen\u001B[49m\u001B[43m(\u001B[49m\u001B[43mpath\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mrb\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m \u001B[38;5;28;01mas\u001B[39;00m f:\n\u001B[1;32m     96\u001B[0m             loader \u001B[38;5;241m=\u001B[39m pickle\u001B[38;5;241m.\u001B[39mload(f)\n\u001B[1;32m     97\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n",
      "File \u001B[0;32m~/miniforge3/envs/EPH/lib/python3.8/gzip.py:58\u001B[0m, in \u001B[0;36mopen\u001B[0;34m(filename, mode, compresslevel, encoding, errors, newline)\u001B[0m\n\u001B[1;32m     56\u001B[0m gz_mode \u001B[38;5;241m=\u001B[39m mode\u001B[38;5;241m.\u001B[39mreplace(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mt\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m     57\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(filename, (\u001B[38;5;28mstr\u001B[39m, \u001B[38;5;28mbytes\u001B[39m, os\u001B[38;5;241m.\u001B[39mPathLike)):\n\u001B[0;32m---> 58\u001B[0m     binary_file \u001B[38;5;241m=\u001B[39m \u001B[43mGzipFile\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfilename\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mgz_mode\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcompresslevel\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     59\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;28mhasattr\u001B[39m(filename, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mread\u001B[39m\u001B[38;5;124m\"\u001B[39m) \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mhasattr\u001B[39m(filename, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mwrite\u001B[39m\u001B[38;5;124m\"\u001B[39m):\n\u001B[1;32m     60\u001B[0m     binary_file \u001B[38;5;241m=\u001B[39m GzipFile(\u001B[38;5;28;01mNone\u001B[39;00m, gz_mode, compresslevel, filename)\n",
      "File \u001B[0;32m~/miniforge3/envs/EPH/lib/python3.8/gzip.py:173\u001B[0m, in \u001B[0;36mGzipFile.__init__\u001B[0;34m(self, filename, mode, compresslevel, fileobj, mtime)\u001B[0m\n\u001B[1;32m    171\u001B[0m     mode \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mb\u001B[39m\u001B[38;5;124m'\u001B[39m\n\u001B[1;32m    172\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m fileobj \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m--> 173\u001B[0m     fileobj \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmyfileobj \u001B[38;5;241m=\u001B[39m \u001B[43mbuiltins\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mopen\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfilename\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmode\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01mor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mrb\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[1;32m    174\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m filename \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m    175\u001B[0m     filename \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mgetattr\u001B[39m(fileobj, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mname\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124m'\u001B[39m)\n",
      "\u001B[0;31mFileNotFoundError\u001B[0m: [Errno 2] No such file or directory: 'datasets/citeseer.pkl.gzip'"
     ]
    }
   ],
   "source": [
    "file_path = (\n",
    "    Path(config[\"dataset_params\"][\"dataset_path\"])\n",
    "    / f\"{config['dataset_params']['dataset_name']}.pkl.gzip\"\n",
    ")\n",
    "if \"percent\" in config[\"dataset_params\"].keys():\n",
    "    data_module = ProbabilisticEPHDataModule.from_pickle(\n",
    "        str(file_path),\n",
    "        dtype=torch.float32,\n",
    "        **config[\"dataset_params\"],\n",
    "    )\n",
    "else:\n",
    "    data_module = EPHDataModule.from_pickle(\n",
    "        str(file_path),\n",
    "        dtype=torch.float32,\n",
    "        **config[\"dataset_params\"],\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unexpected indent (3143371668.py, line 9)",
     "output_type": "error",
     "traceback": [
      "\u001B[0;36m  Cell \u001B[0;32mIn[9], line 9\u001B[0;36m\u001B[0m\n\u001B[0;31m    if \"out_dir\" in config.keys():\u001B[0m\n\u001B[0m    ^\u001B[0m\n\u001B[0;31mIndentationError\u001B[0m\u001B[0;31m:\u001B[0m unexpected indent\n"
     ]
    }
   ],
   "source": [
    "trainer = pl.Trainer(\n",
    "    gpus=1 if config[\"training_params\"][\"use_gpu\"] else 0,\n",
    "    max_epochs=config[\"training_params\"][\"max_epochs\"],\n",
    "    accumulate_grad_batches=config[\"training_params\"][\"gumbel_samples\"],\n",
    "    check_val_every_n_epoch=config[\"training_params\"][\"val_every\"],\n",
    "    log_every_n_steps=1,\n",
    ")\n",
    "\n",
    "if \"out_dir\" in config.keys():\n",
    "    out_dir = config[\"out_dir\"]\n",
    "else:\n",
    "    out_dir = trainer.log_dir\n",
    "\n",
    "init_from = get_initial_hierarchy(data_module, **config[\"model_params\"])\n",
    "shape = init_from[0].shape\n",
    "model = EPH(num_nodes=shape[1], initialize_from=init_from, **config[\"model_params\"])\n",
    "\n",
    "trainer.fit(\n",
    "    model,\n",
    "    data_module,\n",
    ")\n",
    "loss_function = Losses[config[\"model_params\"][\"loss\"]]\n",
    "\n",
    "A = model.best_A_u_cont.detach().cpu()\n",
    "B = model.best_B_u_cont.detach().cpu()\n",
    "A_cont = model.best_A_u_cont.detach().cpu()\n",
    "B_cont = model.best_B_u_cont.detach().cpu()\n",
    "T = best_tree(A_cont.numpy(), B_cont.numpy())\n",
    "\n",
    "best_A = os.path.join(out_dir, \"best_A.npy\")\n",
    "best_B = os.path.join(out_dir, \"best_B.npy\")\n",
    "np.savez(best_A, A)\n",
    "np.savez(best_B, B)\n",
    "print(f\"Saved best A in {best_A}\")\n",
    "print(f\"Saved best B in {best_B}\")\n",
    "\n",
    "graph = next(iter(data_module.test_dataloader()))\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    print(\"Dasgupta cost: \", model.compute_dasgupta(graph, A, B).metric)\n",
    "    print(\"TSD: \", compute_skn_tsd(graph, T))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}